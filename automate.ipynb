{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54bf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "DB_CONN_STR = (\n",
    "    \"DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "    \"SERVER=BHARAT_DUNGRIYA\\\\SQLEXPRESS;\"\n",
    "    \"DATABASE=FinGuardDB;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    "    \"Encrypt=Optional;\"\n",
    "    \"TrustServerCertificate=yes;\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8742bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_loaded_date():\n",
    "    conn = pyodbc.connect(DB_CONN_STR)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT LastLoadedDate\n",
    "        FROM etl_load_control\n",
    "        WHERE TableName = 'fraud_transactions'\n",
    "    \"\"\")\n",
    "\n",
    "    last_date = cur.fetchone()[0]\n",
    "    conn.close()\n",
    "    return last_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00caa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_incremental_data(file_path, last_loaded_date):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df[\"trans_date_trans_time\"] = pd.to_datetime(\n",
    "        df[\"trans_date_trans_time\"],\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # ðŸ”¥ FILTER NEW DATA ONLY\n",
    "    df_new = (\n",
    "    df[df[\"trans_date_trans_time\"] > last_loaded_date]\n",
    "    .copy()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"RowNum\"})\n",
    ")\n",
    "\n",
    "\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9379e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = extract_incremental_data(\n",
    "    r\"C:\\Users\\bhara\\OneDrive\\Desktop\\Automated ETL & Data Quality Pipeline for Financial Transactions\\fraudTrain.csv\",\n",
    "    get_last_loaded_date()\n",
    ")\n",
    "\n",
    "if df_new.empty:\n",
    "    print(\"âœ… No new data found. ETL skipped.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0c5c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to SQL Server successfully!\n",
      "Total rows to load: 6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhara\\OneDrive\\Desktop\\Automated ETL & Data Quality Pipeline for Financial Transactions\\Financial_data_anomalies_Check.py:334: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new.rename(columns={\"index\": \"RowNum\"}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Incremental ETL completed successfully\n",
      "âœ… Latest issues saved to CSV: C:\\Users\\bhara\\OneDrive\\Desktop\\Automated ETL & Data Quality Pipeline for Financial Transactions\\DQ_ISSUE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\AppData\\Local\\Temp\\ipykernel_6564\\1419583833.py:39: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_issues = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "from Financial_data_anomalies_Check import *\n",
    "\n",
    "FILE_PATH = r\"C:\\Users\\bhara\\OneDrive\\Desktop\\Automated ETL & Data Quality Pipeline for Financial Transactions\\fraudTrain.csv\"\n",
    "\n",
    "last_date = get_last_loaded_date()\n",
    "df_new = extract_incremental_data(FILE_PATH, last_date)\n",
    "\n",
    "if df_new.empty:\n",
    "    print(\"âœ… No new data. ETL skipped.\")\n",
    "else:\n",
    "    issues = detect_issues(df_new)\n",
    "    df_new = clean_data(df_new)\n",
    "\n",
    "    load_raw(df_new)\n",
    "    log_issues(issues)\n",
    "    load_clean(df_new)\n",
    "\n",
    "    update_last_loaded_date(df_new)\n",
    "    print(\"âœ… Incremental ETL completed successfully\")\n",
    "#**************************----------------------****************************----------------------------**************************************\n",
    "\n",
    "\n",
    "\n",
    "# for sending mails for issues \n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_latest_issues():\n",
    "    \"\"\"\n",
    "    Fetch the issues logged in the last ETL run.\n",
    "    \"\"\"\n",
    "    conn = pyodbc.connect(DB_CONN_STR)\n",
    "    query = \"\"\"\n",
    "        SELECT RowNum, ColumnName, IssueType, IssueDescription\n",
    "        FROM dq_issues\n",
    "        WHERE DetectedAt >= DATEADD(MONTH, -1, GETDATE())  -- last 1 month\n",
    "        ORDER BY RowNum\n",
    "    \"\"\"\n",
    "    df_issues = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df_issues\n",
    "# Step 1: Get latest issues from SQL Server\n",
    "df_issues = fetch_latest_issues()\n",
    "\n",
    "# Step 2: Check if there are any issues\n",
    "if df_issues.empty:\n",
    "    print(\"âœ… No new data quality issues found.\")\n",
    "else:\n",
    "    # Step 3: Write to CSV\n",
    "    output_file = r\"C:\\Users\\bhara\\OneDrive\\Desktop\\Automated ETL & Data Quality Pipeline for Financial Transactions\\DQ_ISSUE.csv\"\n",
    "    df_issues.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… Latest issues saved to CSV: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
